{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "from refinery import Client\n",
    "from embedders.extraction.contextual import TransformerTokenEmbedder\n",
    "from sequencelearn.sequence_tagger import CRFTagger\n",
    "\n",
    "import truss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Connecting to https://app.kern.ai\u001b[0m\n",
      "\u001b[38;5;2m✔ Logged in to system.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If you run the application locally, you need to include the uri https//localhost:4455\n",
    "client = Client.from_secrets_file(\"secrets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the project data into a DataFrame\n",
    "df = client.get_record_export(tokenize=False)\n",
    "# if you set tokenize=True (default), the project-specific \n",
    "# spaCy tokenizer will process your textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the manual labels from the DataFrame\n",
    "df_yes = df[df[\"__seen__MANUAL\"] == \"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should you get a CUDA error, you can block GPU usage with\n",
    "# os.environ[' CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have any SpaCy models on your machine, you can download them like this:\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Use embedders to easily convert your raw data. Transformer models will be downloaded automatically.\n",
    "embedder = TransformerTokenEmbedder(\"distilbert-base-uncased\", \"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, might take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches ...:   0%|                                                                                                                                                           | 0/2 [00:00<?, ?it/s]/Users/jhoetter/opt/anaconda3/envs/demo-ner-ml-week/lib/python3.10/site-packages/embedders/util.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  yield documents[idx : min(idx + batch_size, length)]\n",
      "Encoding batches ...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:11<00:00,  5.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract the corpus and the labels from the DataFrame\n",
    "corpus = df_yes['headline']\n",
    "labels = df_yes['headline__entities__MANUAL']\n",
    "\n",
    "# use embedders to easily convert your raw data\n",
    "embedder = TransformerTokenEmbedder(\"distilbert-base-uncased\", \"en_core_web_sm\")\n",
    "\n",
    "# contains a list of ragged shape [num_texts, num_tokens (text-specific), embedding_dimension]\n",
    "embeddings = embedder.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings for training:\n",
      "num_epochs     500\n",
      "learning_rate  1e-05\n",
      "momentum       0.9\n",
      "random_seed    727012968934355971\n",
      "Epoch 1/500. Loss inf\n",
      "Epoch 11/500. Loss 2289.665771484375\n",
      "Epoch 21/500. Loss 779.0813598632812\n",
      "Epoch 31/500. Loss 460.1942138671875\n",
      "Epoch 41/500. Loss 340.2244873046875\n",
      "Epoch 51/500. Loss 255.57073974609375\n",
      "Epoch 61/500. Loss 198.02032470703125\n",
      "Epoch 71/500. Loss 154.21685791015625\n",
      "Epoch 81/500. Loss 118.7591552734375\n",
      "Epoch 91/500. Loss 92.01459503173828\n",
      "Epoch 101/500. Loss 72.25796508789062\n",
      "Epoch 111/500. Loss 57.7586669921875\n",
      "Epoch 121/500. Loss 47.1136474609375\n",
      "Epoch 131/500. Loss 39.15240478515625\n",
      "Epoch 141/500. Loss 33.07228088378906\n",
      "Epoch 151/500. Loss 28.351837158203125\n",
      "Epoch 161/500. Loss 24.662490844726562\n",
      "Epoch 171/500. Loss 21.69512939453125\n",
      "Epoch 181/500. Loss 19.28741455078125\n",
      "Epoch 191/500. Loss 17.339141845703125\n",
      "Epoch 201/500. Loss 15.697921752929688\n",
      "Epoch 211/500. Loss 14.354385375976562\n",
      "Epoch 221/500. Loss 13.180465698242188\n",
      "Epoch 231/500. Loss 12.204925537109375\n",
      "Epoch 241/500. Loss 11.328628540039062\n",
      "Epoch 251/500. Loss 10.59735107421875\n",
      "Epoch 261/500. Loss 9.95098876953125\n",
      "Epoch 271/500. Loss 9.350631713867188\n",
      "Epoch 281/500. Loss 8.84747314453125\n",
      "Epoch 291/500. Loss 8.362625122070312\n",
      "Epoch 301/500. Loss 7.9568023681640625\n",
      "Epoch 311/500. Loss 7.59161376953125\n",
      "Epoch 321/500. Loss 7.2228546142578125\n",
      "Epoch 331/500. Loss 6.91802978515625\n",
      "Epoch 341/500. Loss 6.6397705078125\n",
      "Epoch 351/500. Loss 6.383056640625\n",
      "Epoch 361/500. Loss 6.1178741455078125\n",
      "Epoch 371/500. Loss 5.9005889892578125\n",
      "Epoch 381/500. Loss 5.7038116455078125\n",
      "Epoch 391/500. Loss 5.5190277099609375\n",
      "Epoch 401/500. Loss 5.3063812255859375\n",
      "Epoch 411/500. Loss 5.144622802734375\n",
      "Epoch 421/500. Loss 4.9901580810546875\n",
      "Epoch 431/500. Loss 4.84661865234375\n",
      "Epoch 441/500. Loss 4.7141876220703125\n",
      "Epoch 451/500. Loss 4.5634613037109375\n",
      "Epoch 461/500. Loss 4.440887451171875\n",
      "Epoch 471/500. Loss 4.3338775634765625\n",
      "Epoch 481/500. Loss 4.2276153564453125\n",
      "Epoch 491/500. Loss 4.1236419677734375\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tagger and fit to the data\n",
    "tagger = CRFTagger(verbose=True, learning_rate=0.00001, num_epochs=500)\n",
    "tagger.fit(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, might take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches ...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['B-people',\n",
       "  'I-people',\n",
       "  'OUTSIDE',\n",
       "  'OUTSIDE',\n",
       "  'OUTSIDE',\n",
       "  'OUTSIDE',\n",
       "  'OUTSIDE',\n",
       "  'B-GPE',\n",
       "  'I-GPE']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the model\n",
    "embs = embedder.transform([\"Barack Obama is the president of the United States\"])\n",
    "tagger.predict(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jhoetter/repos/demo-ner-ml-week/ner-truss/data/model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will save the model to our Truss. Replace \"ner-truss\" if your truss is named differently\n",
    "parent_path = pathlib.Path('ner-deployment.ipynb').parent.resolve()\n",
    "save_path = os.path.join(parent_path, \"ner-truss\", \"data\", \"model.joblib\")\n",
    "joblib.dump(tagger, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path the truss is saved in\n",
    "truss_name = \"ner-truss\"\n",
    "truss_parent = pathlib.Path(truss_name).parent.resolve()\n",
    "truss_path = os.path.join(truss_parent, truss_name)\n",
    "\n",
    "# Load in the truss\n",
    "tr = truss.from_directory(\"ner-truss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, might take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches ...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get new predictions on the truss\n",
    "sentence = [\"Facebook is not operating in Russia anymore\"]\n",
    "predictions = tr.server_predict({\"inputs\": embedder.transform(sentence)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [['B-organization', 'OUTSIDE', 'OUTSIDE', 'OUTSIDE', 'OUTSIDE', 'B-GPE', 'OUTSIDE']]}\n"
     ]
    }
   ],
   "source": [
    "# Print out the entities we found in the \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model, might take some time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches ...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [[\"B-organization\", \"OUTSIDE\", \"OUTSIDE\", \"OUTSIDE\", \"OUTSIDE\", \"B-GPE\", \"OUTSIDE\"]]}\n"
     ]
    }
   ],
   "source": [
    "# Call the running NER model from Azure container instance\n",
    "import json \n",
    "import requests\n",
    "\n",
    "input_dict = {\"inputs\": embedder.transform(sentence)}\n",
    "with open(\"data.json\", \"w\") as fp:\n",
    "    json.dump(input_dict, fp)\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "with open(\"data.json\") as f:\n",
    "    data = f.read().replace(\"\\n\", \"\")\n",
    "\n",
    "response  = requests.post(\"http://20.166.114.59:8080/v1/models/model:predict\", headers=headers, data=data)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "59227a170818b611e3504f2e8a6a3aebc7ebe14d3a7799f5a72d26d234398cb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
